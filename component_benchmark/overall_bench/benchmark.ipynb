{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "import numpy as np\n",
    "import _mgard as mgard\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Slicer:\n",
    "\n",
    "    # default 引数\n",
    "    def __init__(self,filename=\"/scratch/aoyagir/step1_500_test.h5\") -> None:\n",
    "        self.filename = filename\n",
    "        self.file = h5py.File(filename, 'r')\n",
    "        self.dataset = self.file['data']\n",
    "        print(self.dataset.shape)\n",
    "\n",
    "    # Access specific elements in the concatenated array\n",
    "    def access_array_element(self,timestep, x, y, z):\n",
    "        element = self.dataset[timestep, x, y, z]\n",
    "        return element\n",
    "\n",
    "    # Access a subset of the concatenated array\n",
    "    def slice_multiple_step(self, file, timestep_start, timestep_end, x_start, x_end, y_start, y_end, z_start, z_end):\n",
    "        subset = self.dataset[timestep_start:timestep_end, x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "        return subset\n",
    "    \n",
    "    # slice siingle step\n",
    "    def slice_single_step(self, timestep,  x_start, x_end, y_start, y_end, z_start, z_end):\n",
    "        subset = self.dataset[timestep,  x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "        retsubset = np.squeeze(subset)\n",
    "        return retsubset\n",
    "\n",
    "    # slice sigle step by size\n",
    "    def get_xyz_offset_by_size(self, size):\n",
    "        # 100MB -> 「100/(sizeof(float))」個のデータ\n",
    "        sizeFloat = 4 # byte\n",
    "        return int((size/sizeFloat)**(1/3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 1024, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "slicer = Slicer(\"/scratch/aoyagir/step1_256_test_0902.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config for hardware\n",
    "\n",
    "configGPU = mgard.Config()\n",
    "configGPU.dev_type = mgard.DeviceType.CUDA\n",
    "\n",
    "configSingle = mgard.Config()\n",
    "configSingle.dev_type = mgard.DeviceType.SERIAL\n",
    "\n",
    "configOMP = mgard.Config()\n",
    "configOMP.dev_type = mgard.DeviceType.OPENMP\n",
    "\n",
    "deviceConfig = [(configSingle,\"single\"),(configOMP,\"omp\"),(configGPU,\"gpu\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file to write the results\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Format the current date and time as a string\n",
    "timestamp = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create the file name based on the timestamp\n",
    "csv_file = f'bench_{timestamp}.txt'\n",
    "\n",
    "import csv\n",
    "\n",
    "header = ['tol', 'OriginalSizeInByte','CompressedSizeInByte','CompRatio','avg_load_time', 'std_dev_load_time','load_throughput'\n",
    "            ,'avg_comp_time', 'std_dev_comp_time','comp_throughput', 'avg_decomp_time',\n",
    "            'std_dev_decomp_time', 'decomp_throughput', 'devName']\n",
    "\n",
    "with open(csv_file, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "0.01\n",
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CompressSize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m avg_decomp_time \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(decomp_exe_times)\n\u001b[1;32m     56\u001b[0m std_dev_decomp_time \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstd(decomp_exe_times)\n\u001b[0;32m---> 58\u001b[0m row_data \u001b[39m=\u001b[39m [tol, OriginalSize, CompressedSize,OriginalSize\u001b[39m/\u001b[39mCompressSize,\n\u001b[1;32m     59\u001b[0m             avg_load_time, std_dev_load_time,OriginalSize\u001b[39m/\u001b[39mavg_load_time,\n\u001b[1;32m     60\u001b[0m             avg_comp_time, std_dev_comp_time,OriginalSize\u001b[39m/\u001b[39mavg_comp_time,\n\u001b[1;32m     61\u001b[0m             avg_decomp_time, std_dev_decomp_time, OriginalSize\u001b[39m/\u001b[39mavg_decomp_time, \n\u001b[1;32m     62\u001b[0m             devName]\n\u001b[1;32m     63\u001b[0m \u001b[39m# Write the data row\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(csv_file, \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m, newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CompressSize' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the number of repetitions and initialize a list for results\n",
    "num_repetitions = 3\n",
    "results = []\n",
    "\n",
    "# Wrap your outer loop with tqdm to create a progress bar\n",
    "for devtuple in tqdm(deviceConfig): # 3 iteration\n",
    "    dev = devtuple[0]\n",
    "    devName = devtuple[1]\n",
    "    for tol in np.arange(0, 1, 0.01): # 100 iteration\n",
    "        if tol == 0:\n",
    "            print(\"passed\")\n",
    "            continue\n",
    "        print(tol)\n",
    "        OriginalSize = 1 * 1024 * 1024  # 1MB in bytes\n",
    "\n",
    "        while OriginalSize <= 4000 * 1024 * 1024:  # 4000MB in bytes. 10 iterations\n",
    "            # Your code here\n",
    "            load_exe_times = []  # List to store execution times for each repetition\n",
    "            comp_exe_times = []\n",
    "            decomp_exe_times = []\n",
    "            comp_data_size = None\n",
    "\n",
    "            # get the offset size\n",
    "            offset = slicer.get_xyz_offset_by_size(OriginalSize)\n",
    "            print(offset)\n",
    "            \n",
    "            # Measure the execution time of the loading\n",
    "            start_time = time.time()\n",
    "            original = slicer.slice_single_step(0, 0, offset, 0, offset, 0, offset)\n",
    "            end_time = time.time()\n",
    "            load_time = end_time - start_time\n",
    "            load_exe_times.append(load_time)\n",
    "\n",
    "            for _ in range(num_repetitions):\n",
    "                # Measure the execution time of compressing\n",
    "                comp_start_time = time.time()\n",
    "                compressed = mgard.compress(original, tol, 0, mgard.ErrorBoundType.REL, dev)\n",
    "                comp_end_time = time.time()\n",
    "                comp_exe_times.append(comp_end_time - comp_start_time)\n",
    "                CompressedSize = compressed.nbytes\n",
    "\n",
    "                # Measure the execution time of decompressing\n",
    "                decomp_start_time = time.time()\n",
    "                decompressed = mgard.decompress(compressed, dev)\n",
    "                decomp_end_time = time.time()\n",
    "                decomp_exe_times.append(decomp_end_time - decomp_start_time)\n",
    "\n",
    "            # Calculate average and standard deviation of execution times\n",
    "            avg_load_time = np.mean(load_exe_times)\n",
    "            std_dev_load_time = np.std(load_exe_times)\n",
    "\n",
    "            avg_comp_time = np.mean(comp_exe_times)\n",
    "            std_dev_comp_time = np.std(comp_exe_times)\n",
    "\n",
    "            avg_decomp_time = np.mean(decomp_exe_times)\n",
    "            std_dev_decomp_time = np.std(decomp_exe_times)\n",
    "\n",
    "            row_data = [tol, OriginalSize, CompressedSize,OriginalSize/CompressedSize,\n",
    "                        avg_load_time, std_dev_load_time,OriginalSize/avg_load_time,\n",
    "                        avg_comp_time, std_dev_comp_time,OriginalSize/avg_comp_time,\n",
    "                        avg_decomp_time, std_dev_decomp_time, OriginalSize/avg_decomp_time, \n",
    "                        devName]\n",
    "            # Write the data row\n",
    "            with open(csv_file, \"a\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(row_data)\n",
    "\n",
    "            # Double the size\n",
    "            OriginalSize *= 2\n",
    "            print(row_data)\n",
    "\n",
    "# Convert the results list to a NumPy array for easier manipulation\n",
    "results_array = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
