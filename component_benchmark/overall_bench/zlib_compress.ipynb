{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zlib\n",
    "import socket\n",
    "import _mgard as mgard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Slicer:\n",
    "\n",
    "    # default 引数\n",
    "    def __init__(self,filename=\"/scratch/aoyagir/step1_500_test.h5\") -> None:\n",
    "        self.filename = filename\n",
    "        self.file = h5py.File(filename, 'r')\n",
    "        self.dataset = self.file['data']\n",
    "        print(self.dataset.shape)\n",
    "\n",
    "    # Access specific elements in the concatenated array\n",
    "    def access_array_element(self,timestep, x, y, z):\n",
    "        element = self.dataset[timestep, x, y, z]\n",
    "        return element\n",
    "\n",
    "    # Access a subset of the concatenated array\n",
    "    def slice_multiple_step(self, file, timestep_start, timestep_end, x_start, x_end, y_start, y_end, z_start, z_end):\n",
    "        subset = self.dataset[timestep_start:timestep_end, x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "        return subset\n",
    "    \n",
    "    def slice_single_step(self, timestep,  x_start, x_end, y_start, y_end, z_start, z_end):\n",
    "        subset = self.dataset[timestep,  x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "        retsubset = np.squeeze(subset)\n",
    "        return retsubset\n",
    "    # slice sigle step by size\n",
    "    def get_xyz_offset_by_size(self, size):\n",
    "        # 100MB -> 「100/(sizeof(float))」個のデータ\n",
    "        sizeFloat = 4 # byte\n",
    "        return int((size/sizeFloat)**(1/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 1024, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# slicer instance\n",
    "slicer = Slicer(\"/scratch/aoyagir/step1_256_test_0902.h5\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file to write the results\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Format the current date and time as a string\n",
    "timestamp = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# timestep to conduct the benchmark\n",
    "timestep = 0\n",
    "\n",
    "# Create the file name based on the timestamp\n",
    "csv_file = f'bench_{timestamp}_timestep_{timestep}_lossless_single.txt'\n",
    "\n",
    "import csv\n",
    "\n",
    "header = ['OriginalSizeInByte','CompressedSizeInByte','CompRatio','avg_load_time', 'std_dev_load_time','load_throughput'\n",
    "            ,'avg_comp_time', 'std_dev_comp_time','comp_throughput', 'avg_decomp_time',\n",
    "            'std_dev_decomp_time', 'decomp_throughput']\n",
    "\n",
    "with open(csv_file, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "[1048576, 922814, 1.136280984033619, 0.6103804111480713, 0.0, 1717905.720512429, 0.2031258742014567, 0.1783171345586713, 5162198.090825399, 0.24077526728312174, 0.3285156902293886, 4354998.799635866]\n",
      "80\n",
      "[2097152, 1890239, 1.1094639355129166, 0.029191255569458008, 0.0, 71841788.20297785, 0.15894412994384766, 0.0007748275407531652, 13194271.47602676, 0.017340977986653645, 5.7373350357657594e-05, 120936201.0386068]\n",
      "101\n",
      "[4194304, 3796874, 1.1046729493788838, 0.04001498222351074, 0.0, 104818339.70516281, 0.31445082028706867, 0.0006539608331922133, 13338505.513106734, 0.03483851750691732, 1.9651181236725025e-05, 120392723.34614138]\n",
      "127\n",
      "[8388608, 7513522, 1.1164681490251842, 0.0585787296295166, 0.0, 143202286.10374567, 0.635926882425944, 0.000700711956105609, 13191151.73744347, 0.07275811831156413, 0.004691580349060107, 115294460.53124109]\n",
      "161\n",
      "[16777216, 15203472, 1.1035121451205356, 0.08572006225585938, 0.0, 195720996.444484, 1.3431658744812012, 0.005542037592503328, 12490799.77294704, 0.15549063682556152, 0.014352931256223835, 107898561.24148273]\n",
      "203\n",
      "[33554432, 30410042, 1.1033997256564132, 0.2645430564880371, 0.0, 126839208.88136168, 2.8340378602345786, 0.1522895084741837, 11839796.66285144, 0.31011327107747394, 0.015048508403931215, 108200567.75840876]\n",
      "255\n",
      "[67108864, 60271282, 1.113446765575685, 0.36821818351745605, 0.0, 182252987.50575846, 5.740731875101726, 0.2891847724334963, 11689949.201609565, 0.6410064697265625, 0.017334345751719524, 104692958.9160418]\n",
      "322\n",
      "[134217728, 121208674, 1.107327747847485, 0.392254114151001, 0.0, 342170351.2033323, 11.389850536982218, 0.20922558260135443, 11783976.230785683, 1.3242282072703044, 0.01694430592623136, 101355436.52001604]\n",
      "406\n",
      "[268435456, 241940315, 1.1095110626767597, 0.6942236423492432, 0.0, 386670000.3065556, 22.613595485687256, 0.14699821652785808, 11870534.085121488, 2.688062906265259, 0.06228887963019734, 99862043.91807143]\n",
      "511\n",
      "[536870912, 482163509, 1.113462346234916, 1.200131893157959, 0.0, 447343258.7374279, 46.692553440729775, 0.7103339648316036, 11497998.55519765, 5.289154688517253, 0.003820619388698061, 101504104.8365528]\n",
      "645\n",
      "[1073741824, 975172246, 1.1010791461757823, 1.750011682510376, 0.0, 613562660.5987722, 91.84250672658284, 0.1403136623766506, 11691120.618000476, 11.215492804845175, 0.3777324428589999, 95737373.53173956]\n",
      "812\n",
      "[2147483648, 1955096109, 1.098403110780269, 2.8802578449249268, 0.0, 745587292.3960298, 178.00368475914001, 0.49158214014157986, 12064265.135330196, 21.461461623509724, 0.44536329959032367, 100062320.34297061]\n",
      "1023\n",
      "[4294967296, 3926148560, 1.0939390678584002, 4.745076656341553, 0.0, 905141814.781853, 353.0722927252452, 0.9513407953848866, 12164554.921170974, 43.715134382247925, 0.10104583704466223, 98248978.45319499]\n"
     ]
    }
   ],
   "source": [
    "import zlib\n",
    "import time \n",
    "# Define the number of repetitions and initialize a list for results\n",
    "num_repetitions = 3\n",
    "results = []\n",
    "\n",
    "OriginalSize = 1 * 1024 * 1024  # 1MB in bytes\n",
    "\n",
    "# Wrap your outer loop with tqdm to create a progress bar\n",
    "while OriginalSize <= 8000 * 1024 * 1024:  # 4000MB in bytes. 10 iterations\n",
    "    # Your code here\n",
    "    load_exe_times = []  # List to store execution times for each repetition\n",
    "    comp_exe_times = []\n",
    "    decomp_exe_times = []\n",
    "    comp_data_size = None\n",
    "\n",
    "    # get the offset size\n",
    "    offset = slicer.get_xyz_offset_by_size(OriginalSize)\n",
    "    print(offset)\n",
    "    \n",
    "    # Measure the execution time of the loading\n",
    "    start_time = time.time()\n",
    "    original = slicer.slice_single_step(timestep, 0, offset, 0, offset, 0, offset)\n",
    "    end_time = time.time()\n",
    "    load_time = end_time - start_time\n",
    "    load_exe_times.append(load_time)\n",
    "\n",
    "    for _ in range(num_repetitions):\n",
    "        # Measure the execution time of compressing\n",
    "        comp_start_time = time.time()\n",
    "        compressed_array = zlib.compress(original.tobytes())\n",
    "        comp_end_time = time.time()\n",
    "        comp_exe_times.append(comp_end_time - comp_start_time)\n",
    "        CompressedSize = len(compressed_array)\n",
    "\n",
    "        # Measure the execution time of decompressing\n",
    "        decomp_start_time = time.time()\n",
    "        decompressed_data = zlib.decompress(compressed_array)\n",
    "        decompressed_array = np.frombuffer(decompressed_data, dtype=np.int32).reshape(original.shape)\n",
    "        decomp_end_time = time.time()\n",
    "        decomp_exe_times.append(decomp_end_time - decomp_start_time)\n",
    "\n",
    "    # Calculate average and standard deviation of execution times\n",
    "    avg_load_time = np.mean(load_exe_times)\n",
    "    std_dev_load_time = np.std(load_exe_times)\n",
    "\n",
    "    avg_comp_time = np.mean(comp_exe_times)\n",
    "    std_dev_comp_time = np.std(comp_exe_times)\n",
    "\n",
    "    avg_decomp_time = np.mean(decomp_exe_times)\n",
    "    std_dev_decomp_time = np.std(decomp_exe_times)\n",
    "\n",
    "    row_data = [OriginalSize, CompressedSize,OriginalSize/CompressedSize,\n",
    "                avg_load_time, std_dev_load_time,OriginalSize/avg_load_time,\n",
    "                avg_comp_time, std_dev_comp_time,OriginalSize/avg_comp_time,\n",
    "                avg_decomp_time, std_dev_decomp_time, OriginalSize/avg_decomp_time, \n",
    "                ]\n",
    "    # Write the data row\n",
    "    with open(csv_file, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row_data)\n",
    "\n",
    "    # Double the size\n",
    "    OriginalSize *= 2\n",
    "    print(row_data)\n",
    "\n",
    "# Convert the results list to a NumPy array for easier manipulation\n",
    "results_array = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
