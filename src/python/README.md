# The_Middleware
A middleware to support on-demand massive-scientific-data-visualization 


# HTTP interface

## header type
1. FirstContact (再初期化も含む)

header = {
    'type':'init',
    'offset':BlockOffset,
    'L3Size' : 1000,
    'L4Size': 1000,
    'Policy' :'LRU',
    'FileName' : 'test',
}

L3Sizeが0の時にはoffってことにします。

ここにリプレイスメントポリシーを入れるって感じにしたいと思います。キャッシュサイズも決められるようにしたいと思います。

2. BlockRequest

header = {
    'type':'BlockReq',
    'tol':BlockId[0],
    'timestep':BlockId[1],
    'x': BlockId[2],
    'y': BlockId[3],
    'z': BlockId[4]
}

3. noCompress

header = {
    'type':'noCompress',
    'timestep':BlockId[1],
    'x': BlockId[2],
    'y': BlockId[3],
    'z': BlockId[4]
}

圧縮せずに全部持ってくる感じです！！

4. userPoint


5. getStats



## body
compressed array


## prefetch algorithm
### inclusive
1. 単なるLRU。プリフェッチもなし
2. 適当な一からプリフェッチを開始し、ミスが発生したら、その点から再びプリフェッチを開始するいっぱいになるまで。
いっぱいになった後も続ける？
3. ユーザが見ている点を各プリふぇっちゃーが把握していて、それを中心になんホップかわからないけど、みんなで一緒に動く漢字
### exclusive
4. これがメイン、というか提案手法。オニオンキャッシュ。onion cache
ユーザが見ている地点を各キャッシュが包む感じにする。これが一番効率がいいよね。そして、ユーザの動きも把握している、って感じで。
１－２ホップをL1で
３－４ホップをL2で
５－６ホップをL3で
７－８ホップをL4で
管理するみたいな感じ。
ユーザの動きに合わせて全体がよっこいしょって動く。これ面白いな。

## replacement algorithm
単なるLRU?
ユーザ追尾型？radiusサーチ？

## キャッシュの大きさは一定。これは変わりません

# TODO

## client
- [x] リクエストを連続的に送信
- [x] 統計的に提案手法有意義であることを示すために、様々な解析パターンをどうにか用意しないといけない。どうすればいいのだろうか？--> 連続リクエストとランダムのミックスを使うしかないと思う。
- 現状、クライアントのAPIにリクエストするよりも、それをすっ飛ばして直接サーバにリクエストした方が早く終わる、という結果が出ています。つまり、クライアント側でバグが起こっていますと。どこで起こっているのか、解析しないといけません。そのために、pythonのプロファイラを使いたいと思います。
ー－＞これ、ちゃんといい結果が出るようになったので気にしなくていいです。

```
python -m cProfile -o main.prof my_script.py
```
このように実行することでプロファイルできますと。
さらに、line_profileっていうのもあるから、自分で調べてみて。
- [ ] 連続リクエストとランダムのミックスが対話的解析のリクエストとして妥当性があるのかどうか？そこを示す論文を探さないといけない。
- [ ] 初期コンタクトでサーバからデータの範囲を受信

## server
- [x] 各キャッシュのサイズをクライアント側から設定できるように
- [x] 各キャッシュのOn/Offをクライアント側からできるように
- [x] slicerがインデックス以上を読み込まないように注意。最初にスライサーを起動して各次元を読み込んできてもらって、それを各コンポーネントに渡す感じがいいと思う。
- [x] バグ：リスタートした後、L3Prefetcherが動かないことがある。これ、どうやって解決する？リスタート自体は、別にシステムに必須ではない。
--> これおそらく、ブロックサイズが大きすぎて、GPUが圧縮できないことに起因している気がしています。いや、普通に動いている。問題ない
- [x] 二つのブロックがなんホップ離れているかを計算する関数
- [x] 現在、キャッシュのサイズは、そこに格納できる要素数で規定している。が、そうではなく、GiBで規定できるようにしたい。
- [x] L3キャッシュの使用容量だけど、今は、圧縮前のサイズで計算している。これ、圧縮したデータを追加するようにしてほしい。よろしくお願いします。
- [x] キャッシュミスをしたときに、ミスをした箇所からプリフェッチを再開するみたいな。ミスが生じたときに、そのポイントから再びプリフェッチを始めるようなプログラムを書いてください
- [x] プレイフェッチポリシー、リプレイスメントポリシーを多数用意

- [ ] サーバ側で、キャッシュのヒット率 (ユーザからのリクエストに応じた) を出せるようにしてほしい。これすごく大事。
なんだけど、これやるためには、クライアントから来る2つのリクエスト (ユーザが出すリクエスト、プリフェッチャーが出すリクエスト) の二つを区別する必要があります。そこまで来ると、もうwebsocketで書き直した方が早い気がするのですが。。。えええ。

- [ ] キャッシュのサイズから、最大の半径を計算するプログラムを書いてください。
--> いい感じのところまで来ました。
- [ ] やはりHTTPだとオーバヘッドが大きい。というのも、一回一回コネクションを張らないといけないから。これのせいで、セッションも管理しないといけない。pythonでできるかわからないけど、通信部分も自分で書いた方がいいかもしれない。
- [ ] ユーザの動きを常に把握しながら、そのポイントを中心にプリフェッチをするプログラムを書いてください。
--> 現在、ユーザの位置を通知するインターフェースは作った。あとは、中心を知らせたときに、中心の半径に入っていないやつらを抜きつつ、半径以内にいるのにキャッシュには含まれていないやつらをプリフェッチするプログラムを書いてください。よろしくお願いします。


## overall
- [x] シンギュラリティーコンテナを作る。たのむ。動いてくれ。clientはsharkとかで動かそう。って話だ。
ー－＞解決
- [x] バグの個所を先生に見てもらう-->解決。

- [ ] 一回、評価をしたい。マジで。

- [ ] wayを追加？どうやって？
- [ ] onion-cache